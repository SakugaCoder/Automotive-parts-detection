{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import absolute_import, division, print_function\n",
    "\n",
    "#Importar libreria de tensor flow\n",
    "import tensorflow as tf\n",
    "\n",
    "#Importar libreria de keras de la libreria tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "#librerias adicionales\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creaci贸n de objeto keras.datasets.fashion_mnist\n",
    "fashion_minist = keras.datasets.fashion_mnist\n",
    "#Carga de imagenes y etiquetas de entrenameinto respectivamente (Devuelve cuatro 'numpy array')\n",
    "(imagenes_entrenamiento,etiquetas_entrenamiento) , (imagenes_prueba,etiquetas_prueba) = fashion_minist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creaci贸n de una lista con las clases del clasificador\n",
    "clases = ['T-Shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt',\n",
    "         'Sneaker','Bag','Ankle boot']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalamiento de todas las imagenes (Entrenamiento y prueba) las valores de entre 0 a 1\n",
    "#por convenci贸n para alimentar la red nuronal\n",
    "imagenes_entrenamiento = imagenes_entrenamiento / 255.0\n",
    "imagenes_prueba = imagenes_prueba / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noname/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Construcci贸n del modelo clasificador\n",
    "modelo = keras.Sequential()\n",
    "\n",
    "#Capa para convertir la imagen 2d en 1d\n",
    "modelo.add(keras.layers.Flatten(input_shape = (28,28)))\n",
    "#Capa prufunda de 128 neuronas\n",
    "modelo.add(keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "#Capa profunda final de 10 neuronas (Las diez clases de ropa)\n",
    "modelo.add(keras.layers.Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilar el modelo\n",
    "modelo.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 34s 569us/sample - loss: 0.4910 - acc: 0.8276\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 30s 508us/sample - loss: 0.3741 - acc: 0.8651\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 32s 526us/sample - loss: 0.3364 - acc: 0.8775\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 31s 517us/sample - loss: 0.3146 - acc: 0.8845\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 33s 543us/sample - loss: 0.2971 - acc: 0.8905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f519057fe10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenar el modelo\n",
    "modelo.fit(imagenes_entrenamiento,etiquetas_entrenamiento,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 287us/sample - loss: 0.3495 - acc: 0.8741\n",
      "Efectividad de la prueba : 0.8741000294685364\n"
     ]
    }
   ],
   "source": [
    "#Evaluar efectividad\n",
    "prueba_perdida, effectividad_prueba = modelo.evaluate(imagenes_prueba,etiquetas_prueba)\n",
    "print(\"Efectividad de la prueba : {}\".format(effectividad_prueba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones para la imagen 100: [[7.0889887e-06 3.7671973e-11 1.2503291e-02 2.1582146e-04 4.8020415e-02\n",
      "  2.6703690e-08 9.3925273e-01 3.2863752e-09 2.1131460e-07 4.5752512e-07]]\n",
      "Categoria:Shirt \n",
      "Valor real:Shirt\n"
     ]
    }
   ],
   "source": [
    "#Predecir valores de una sola imagen:\n",
    "n_imagen = 3125\n",
    "img = imagenes_prueba[n_imagen]\n",
    "imagen = np.expand_dims(img,0)\n",
    "valor_real = etiquetas_prueba[n_imagen]\n",
    "predicciones = modelo.predict(imagen)\n",
    "\n",
    "print(\"Predicciones para la imagen 100: {}\".format(predicciones))\n",
    "\n",
    "print(\"Categoria:{} \\nValor real:{}\".format(clases[np.argmax(predicciones)],clases[valor_real]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categoria:Bag Valor \n",
      "real:Bag\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
